{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/menouahmad/bonus-III/blob/main/bonus_hot_dog_completed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained Models in an app\n",
        "\n",
        "This problem is motivated by the Silicon Valley sketch.  Your goal is to build a similar app with a fine tuned model from torchvision deployed through a streamlit."
      ],
      "metadata": {
        "id": "usIbvk3SaPv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "XrxndmKRVNMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YouTubeVideo(id = 'tWwCK95X6go')"
      ],
      "metadata": {
        "id": "AcgnEe21XLhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today we will use a dataset to determine whether or not an image is a hotdog.  Dataset link: [link](https://drive.google.com/drive/folders/1d2SelwjIGAtYnui_yczzaTL61eF_oLH_?usp=sharing)"
      ],
      "metadata": {
        "id": "K8jYMnWuWBj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BEGINNING**: To get started, create a basic streamlit app that accepts an image from the user and displays it on the screen."
      ],
      "metadata": {
        "id": "7hOn5lFzcQ8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "AwkOfzlJccKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/drive/MyDrive/hotdogs/data/hotdog-nothotdog/test/hotdog/1501.jpg'"
      ],
      "metadata": {
        "id": "PL6ap4jHccH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4f08Sy2pccE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imread(test_path)"
      ],
      "metadata": {
        "id": "pjo3s43LccCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pretrained Models\n",
        "\n",
        "An example of a pretrained model is that of the ResNet through `torchvision.models`.  Below is an outline of a streamlit app to deploy the model. You should fine tune this model using the hot dog data and deploy a model that allows a user to take a picure with their camera or upload an image and returns a voice stating whether the image is a hot dog or not a hot dog.  How would you improve Jinyang's app to make the rest of the team happy?  (**HINT**: [this](https://huggingface.co/datasets/Codatta/MM-Food-100K))"
      ],
      "metadata": {
        "id": "IjuDsfL6aX-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**: ResNet\n",
        "\n",
        "- [link](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet50.html)"
      ],
      "metadata": {
        "id": "5bAYwwEwasWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from torchvision.models import\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "st.header('Hot Dogs!')\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Pick a picture\")\n",
        "model = ''\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = #load the image\n",
        "    #prepare the image\n",
        "    #pass through the model\n",
        "    #make prediction\n",
        "    #speak!\n",
        "    \n",
        "```"
      ],
      "metadata": {
        "id": "J-BOZcJOWpLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_basic.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "\n",
        "st.header(\"hot dogs!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"pick a picture\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(img, caption=\"your image\", use_container_width=True)\n"
      ],
      "metadata": {
        "id": "YAifzR38WpI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_pretrained.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "st.header(\"hot dogs!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"pick a picture\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "# load pretrained model\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "model = resnet50(weights=weights)\n",
        "model.eval()\n",
        "\n",
        "preprocess = weights.transforms()\n",
        "categories = weights.meta[\"categories\"]\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(img, caption=\"your image\", use_container_width=True)\n",
        "\n",
        "    x = preprocess(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = logits.softmax(dim=1)[0]\n",
        "\n",
        "    top_prob, top_idx = torch.max(probs, dim=0)\n",
        "    label = categories[int(top_idx)]\n",
        "\n",
        "    if \"hotdog\" in label.lower():\n",
        "        st.success(f\"hot dog ({top_prob.item():.1%} sure)\")\n",
        "    else:\n",
        "        st.error(f\"not hot dog (top guess: {label}, {top_prob.item():.1%})\")\n"
      ],
      "metadata": {
        "id": "UKz1DIKYdP2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "# if you are in colab and your data is in google drive, uncomment these two lines:\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/hotdogs/data/hotdog-nothotdog\"\n",
        "\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"valid\")  # some datasets use \"val\"; change if needed\n",
        "\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "mean = weights.meta[\"mean\"]\n",
        "std = weights.meta[\"std\"]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "])\n",
        "\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=train_tfms)\n",
        "val_ds = datasets.ImageFolder(val_dir, transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "train_ds.class_to_idx, train_ds.classes\n"
      ],
      "metadata": {
        "id": "pUXV-IFJdP0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = resnet50(weights=weights)\n",
        "\n",
        "# freeze backbone\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# replace the classifier head (2 classes: hotdog vs nothotdog)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "def accuracy_from_logits(logits, y):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    return (preds == y).float().mean().item()\n",
        "\n",
        "def run_epoch(loader, training):\n",
        "    if training:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        if training:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(training):\n",
        "            logits = model(x)\n",
        "            loss = loss_fn(logits, y)\n",
        "\n",
        "            if training:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += accuracy_from_logits(logits, y)\n",
        "        n_batches += 1\n",
        "\n",
        "    return total_loss / n_batches, total_acc / n_batches\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(1, epochs + 1):\n",
        "    train_loss, train_acc = run_epoch(train_loader, training=True)\n",
        "    val_loss, val_acc = run_epoch(val_loader, training=False)\n",
        "    print(f\"epoch {epoch}/{epochs} | train acc: {train_acc:.3f} | val acc: {val_acc:.3f}\")\n",
        "\n",
        "# save the fine tuned head + frozen backbone weights\n",
        "torch.save(\n",
        "    {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"class_to_idx\": train_ds.class_to_idx,\n",
        "        \"mean\": mean,\n",
        "        \"std\": std,\n",
        "    },\n",
        "    \"hotdog_resnet50_finetuned.pt\",\n",
        ")\n",
        "\n",
        "\"saved hotdog_resnet50_finetuned.pt\"\n"
      ],
      "metadata": {
        "id": "G0Mp8B-BdPx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_finetuned.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "\n",
        "st.header(\"hot dogs!\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"pick a picture\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "# try to load a fine tuned model if you trained it in the notebook\n",
        "ckpt_path = \"hotdog_resnet50_finetuned.pt\"\n",
        "\n",
        "weights = ResNet50_Weights.DEFAULT\n",
        "model = resnet50(weights=weights)\n",
        "\n",
        "# default labels (imagenet)\n",
        "labels = weights.meta[\"categories\"]\n",
        "\n",
        "# if we have a fine tuned checkpoint, switch to binary labels\n",
        "if torch.cuda.is_available():\n",
        "    map_location = \"cuda\"\n",
        "else:\n",
        "    map_location = \"cpu\"\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    img = Image.open(uploaded_file).convert(\"RGB\")\n",
        "    st.image(img, caption=\"your image\", use_container_width=True)\n",
        "\n",
        "try:\n",
        "    ckpt = torch.load(ckpt_path, map_location=map_location)\n",
        "    model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    labels = [\"hotdog\", \"not hotdog\"]\n",
        "\n",
        "    mean = ckpt.get(\"mean\", weights.meta[\"mean\"])\n",
        "    std = ckpt.get(\"std\", weights.meta[\"std\"])\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=mean, std=std),\n",
        "    ])\n",
        "    st.caption(\"using fine tuned model\")\n",
        "except Exception:\n",
        "    preprocess = weights.transforms()\n",
        "    st.caption(\"using imagenet pretrained model\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    x = preprocess(img).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = logits.softmax(dim=1)[0]\n",
        "\n",
        "    top_prob, top_idx = torch.max(probs, dim=0)\n",
        "    label = labels[int(top_idx)]\n",
        "\n",
        "    if \"hotdog\" in label.lower():\n",
        "        st.success(f\"hot dog ({top_prob.item():.1%} sure)\")\n",
        "    else:\n",
        "        st.error(f\"not hot dog ({top_prob.item():.1%} sure)\")\n"
      ],
      "metadata": {
        "id": "UWZGItQ7dPRF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}